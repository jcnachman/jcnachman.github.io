<h1>Classification and Supervised Learning: Will a Chicago restaurant pass or fail its food safety inspection?</h1>	


In week 3 at Metis, we were tasked with solving a Classification problem of our choosing to present at the end of Week 4.


**The Premise and Goal:**

Chicago is a huge foodie destination that has over 7,300 restaurants. The Department of Public Health conducts inspections across the city. ~ 3 dozen inspectors are responsible for checking these establishments. Additionally, they are in charge of inspecting other food establishments, not just restaurants. So, the number of inspections per person is really closer to 400.

The Department of Public Health has collected the results of ~ 200,000 health inspections from January 1, 2010 to the present. I also collected Median Household Income in Chicago, IL by Zip Code. 

With this information and using classification models, I was able to discern which restaurant features are most likely to have an impact on whether a restaurant will pass or fail its health inspection in hopes that the result is that food establishments that are probably going to fail their inspection are more likely to be discovered earlier by the Department of Public Health's inspectors.

**Workflow:**

The city of Chicago Data portal is free and open sourced. As one of my resources, I was able to collect data from the data.cityofchicago.org site:

- [Food Inspections Dataset](https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5/data)

I also gathered median household income from ZipAtlas.com:

- [Median Household Income in Chicago, IL by Zip Code](http://zipatlas.com/us/il/chicago/zip-code-comparison/median-household-income.htm)

Using these data sets I looked at the following features for ~200K restaurant inspections to predict results - Pass or Fail:

- Risk category, from 1, 2, 3, with 3 being the highest risk, indicating the length of time since last inspection

- Type of inspection performed particularly canvass, complaint,  license,  suspected food poisoning (a specific type of complaint-
based inspection); task-force inspection, when an inspection of a bar or tavern is done.

- Inspection date

- Average household income

- The restaurants zip code

- Average zip code population

I separated my features from the target variable, Pass/Fail results, trained, tested, and cross validated my data. I also used gridsearch to hypertune the model’s parameters.

I dealt with class imbalance, by upsampling my minority class, which were the fails, and retested my models after classes were balanced.

I looked at feature importance and compared the outputs of the Decision Tree and Random Forest classifiers, which were pretty comparable.

**Results:**


I tested several classification models, but I eventually ended up with a random forest classification model that proved to perform the best.

Random forests are an ensemble learning method for classification that works by ensembling decision trees at training time and outputting the class that is the mode of the classes or mean prediction of the individual trees. 

Accuracy was around 76%.

When I ran it against all data it was about 86%.


Here are my predicted results vs. actual results:

<table style="width:100%">
  <tr>
    <th>Pass or Fail?</th>
    <th>Predicted Total Counts</th> 
    <th>Actual Total COunts</th>
  </tr>
  <tr>
    <td>Fail</td>
    <td>96836</td>
    <td>85698</td>
  </tr>
  <tr>
    <td>Pass</td>
    <td>74560</td>
    <td>85698</td>
  </tr>
</table>

The model was 88.5% correct on restaurants failing. Model was 87% correct on restaurants passing.

Fortunately, the model ended up being pretty good at predicting which restaurants would fail and which would pass. Close to 90%.

Since my model performed so well, I wanted to take a look and see where it maybe didn’t perform so well. I looked at my 3 most important features – population, income, and risk, and found some interesting things going on with income.

The average income was $44,487. Then I looked at the difference between the averages for the False Negatives, those that actually passed, but were predicted to fail, and the False Positives, those that actually failed, but were predicted to pass. 

For the False Negatives, my model predicted that the average income neighborhoods would fail their inspection when they actually passed. The FN average was about $1,000 more than the  Average income.

For the False Positives, my model predicted that much higher income neighborhoods would pass their inspection when they actually failed. The FP average was almost $4,000 more than the average income. 

So, this seems to indicate my model has a strong bias towards higher income neighborhoods passing and a slight bias towards lower to average income neighborhoods failing.


**Future Work:**

- Look at other features, like rodent and sanitation complaints.

- Create a flask model to input features to predict  if a restaurant will pass or fail.

**Repository**

Feel free to check out my project 3 repository on github:

https://github.com/jcnachman/Projects




```
---
layout: post
title: Classification and Supervised Learning
---
```

